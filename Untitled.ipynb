{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from IPython.display import display\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_files = ['AAPL.csv', 'MSFT.csv', 'AMD.csv']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "stocks = []\n",
    "target_stock = ''\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in sample_files:\n",
    "    stocks.append(i.split('.')[0])\n",
    "    temp_df = pd.read_csv(i)\n",
    "    if counter == 0:\n",
    "        df['Date'] = temp_df['Date']\n",
    "    if i == 'AAPL.csv':\n",
    "        df['Target'] = temp_df['Close']\n",
    "        target_stock = stocks[counter]\n",
    "        stocks[counter] = 'Target'\n",
    "    else:\n",
    "        df[stocks[counter]] = temp_df['Close']\n",
    "\n",
    "    counter=counter+1\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "\n",
    "df_corr = df.corr()\n",
    "x = []\n",
    "y = []\n",
    "values = df_corr.values\n",
    "for i in range(len(values)):\n",
    "    for j in values[i]:\n",
    "        x.append(j)\n",
    "    for j in values[:, i]:\n",
    "        y.append(j)\n",
    "\n",
    "dendro = ff.create_dendrogram(df_corr.values, labels=stocks)\n",
    "dendro.update_layout(width=600, height=400)\n",
    "\n",
    "heatmap = go.Figure(data=go.Heatmap(x=stocks, y=stocks,\n",
    "                    z=df_corr.values))\n",
    "heatmap.update_layout(width=500, height=500)\n",
    "    \n",
    "heatmap.show()\n",
    "dendro.show()\n",
    "\n",
    "def shape_data(data, input_size):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range((len(data)-input_size)):\n",
    "        indx = i + input_size\n",
    "        if indx > len(data):\n",
    "            break\n",
    "        x.append(data[i:indx])\n",
    "        y.append(data[indx])\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "#Declare constants for the model\n",
    "n_input = 10\n",
    "n_feat = len(df.columns.values)\n",
    "epochs=40\n",
    "n_predict=5\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "#Create a scaler for each of the features\n",
    "def scale_data(stocks, dataframe):\n",
    "    scalers = {}\n",
    "    for i in stocks:\n",
    "        scalers[i] = MinMaxScaler()\n",
    "        scalers[i].fit(np.array(dataframe[i]).reshape((-1, 1)))\n",
    "        dataframe[i] = scalers[i].transform(np.array(dataframe[i]).reshape((-1, 1)))\n",
    "\n",
    "    return dataframe, scalers\n",
    "\n",
    "#Create the model with 4 layers in total\n",
    "model = Sequential()\n",
    "\n",
    "#Drop any null values within the data\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Create a train split -- we will train the model on 80% of the dataset\n",
    "train_split = int(len(df)*.80)\n",
    "\n",
    "#Split the data into the training set\n",
    "df_train = copy.deepcopy(df[:train_split])\n",
    "df_val = copy.deepcopy(df[train_split:])\n",
    "\n",
    "df_train, train_scalers = scale_data(stocks, df_train)\n",
    "df_val, val_scalers = scale_data(stocks, df_val)\n",
    "\n",
    "# train_data = df_train.values\n",
    "# val_data = df_val.values\n",
    "\n",
    "#Format the data into tensors for the model\n",
    "\n",
    "x_train, y_train = shape_data(df_train.values, n_input)\n",
    "x_val, y_val = shape_data(df_val.values, n_input)\n",
    "model.add(LSTM(256, activation='relu', input_shape=x_train.shape[1:], return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(n_feat))\n",
    "model.compile(Adam(lr=.002), loss='mse')\n",
    "\n",
    "print(model.summary)\n",
    "print(\"Training.. Please wait..\")\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Training complete.. Loading results..\")\n",
    "predictions = []\n",
    "batch = np.array(df_train.values[-n_input:]).reshape(1,n_input,n_feat)\n",
    "\n",
    "for i in range(n_predict):\n",
    "    predictions.append(model.predict(batch)[0])\n",
    "    batch = np.append(batch[:, 1: , :], [[predictions[i]]], axis=1)\n",
    "\n",
    "predictions.insert(0, df_train.values[-(n_predict)])\n",
    "\n",
    "temp = pd.DataFrame(predictions, columns=stocks)\n",
    "\n",
    "for i in stocks:\n",
    "    temp[i] = train_scalers[i].inverse_transform(np.array(temp[i]).reshape((-1, 1)))\n",
    "\n",
    "df_predictions = pd.DataFrame(temp.values,\n",
    "                      index=df_train[-(n_predict+1):].index,\n",
    "                          columns=['Target_Prediction' if i == 'Target' else i for i in stocks])\n",
    "\n",
    "df_test = pd.concat([df_train, df_predictions], axis=1)\n",
    "\n",
    "trace1 = go.Scatter(x = df_train.index, y = df['Target'], \n",
    "                    mode = 'lines', name = 'Data')\n",
    "\n",
    "trace2 = go.Scatter(x = df_train[-(n_predict+1):].index, \n",
    "                    y = df_predictions['Target_Prediction'],\n",
    "                    mode = 'lines', name = 'Prediction')\n",
    "\n",
    "layout = go.Layout(title = f'{target_stock} Stock', xaxis = {'title' : \"Date\"},\n",
    "                   yaxis = {'title' : \"Close\"})\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "fig.show()\n",
    "\n",
    "train_data = copy.deepcopy(df)\n",
    "train_data, scalers = scale_data(stocks, train_data)\n",
    "\n",
    "x_train, y_train = shape_data(train_data.values, n_input)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "         epochs=epochs, batch_size=BATCH_SIZE, verbose=0)\n",
    "    \n",
    "predictions = []\n",
    "batch = np.array(train_data[-n_input:]).reshape(1,n_input,n_feat)\n",
    "\n",
    "for i in range(n_predict):\n",
    "    predictions.append(model.predict(batch)[0])\n",
    "    batch = np.append(batch[:, 1: , :], [[predictions[i]]], axis=1)\n",
    "\n",
    "predictions.insert(0, train_data.values[-1])\n",
    "\n",
    "add_dates = [df.index[-1] + DateOffset(days=x) for x in range(0,n_predict+1)]\n",
    "future_dates = pd.DataFrame(index=add_dates[:],columns=df.columns)\n",
    "\n",
    "temp = pd.DataFrame(predictions, columns=stocks)\n",
    "for i in stocks:\n",
    "    temp[i] = scalers[i].inverse_transform(np.array(temp[i]).reshape((-1, 1)))\n",
    "\n",
    "df_predictions = pd.DataFrame(temp.values,\n",
    "                              index=future_dates[-(n_predict+1):].index,\n",
    "                              columns=['Target_Prediction' if i == 'Target' else i for i in stocks])\n",
    "\n",
    "df_proj = pd.concat([df,df_predictions], axis=1)\n",
    "\n",
    "trace1 = go.Scatter(x = df_proj.index, y = df_proj['Target'], mode = 'lines',\n",
    "                    name = 'Data')\n",
    "\n",
    "trace2 = go.Scatter(x = df_proj.index, y = df_proj['Target_Prediction'],\n",
    "                    mode = 'lines', name = 'Prediction')\n",
    "\n",
    "layout = go.Layout(title = f'{target_stock} Stock', xaxis = {'title' : \"Date\"}, \n",
    "                   yaxis = {'title' : \"Close\"})\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
